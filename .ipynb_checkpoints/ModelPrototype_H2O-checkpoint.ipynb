{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:43:23.491069",
     "start_time": "2017-02-08T07:43:23.485469"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "import pandas as pd\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator as gbm\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import log_loss\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:05:21.063318",
     "start_time": "2017-02-08T07:05:21.052528"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>5 mins 31 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.1.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>2 months and 5 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_hamelhusain_a536si</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.417 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.5.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------\n",
       "H2O cluster uptime:         5 mins 31 secs\n",
       "H2O cluster version:        3.10.1.2\n",
       "H2O cluster version age:    2 months and 5 days\n",
       "H2O cluster name:           H2O_from_python_hamelhusain_a536si\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.417 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "Python version:             3.5.2 final\n",
       "--------------------------  ----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()\n",
    "h2o.remove_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:05:21.982383",
     "start_time": "2017-02-08T07:05:21.203392"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/hamelhusain/Dropbox/zidisha/Regression_Dataset_20170125.csv')\n",
    "id_fields = ['borrower_id', 'category_id', 'id']\n",
    "features = [c for c in df.columns if c not in id_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_types = ['int',\n",
    " 'int',\n",
    " 'int',\n",
    " 'real',\n",
    " 'real',\n",
    " 'int',\n",
    " 'int',\n",
    " 'real',\n",
    " 'int',\n",
    " 'real',\n",
    " 'enum',\n",
    " 'int',\n",
    " 'int',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'enum',\n",
    " 'int']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data To H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:40:21.146933",
     "start_time": "2017-02-08T07:40:19.843274"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "HF = h2o.H2OFrame()\n",
    "\n",
    "HDF = HF.from_python(df[non_text_cols])\n",
    "                     #column_types = col_types)\n",
    "\n",
    "hgbm = gbm(nfolds=5, distribution='bernoulli')\n",
    "hyper_params = {'max_depth': [20], 'min_rows': [20, 40], 'ntrees':[30]}\n",
    "grid = H2OGridSearch(hgbm, hyper_params, grid_id='zidisha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:40:30.224385",
     "start_time": "2017-02-08T07:40:30.042825"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set shape: (6260, 30)\n",
      "train set shape: (24880, 30)\n"
     ]
    }
   ],
   "source": [
    "test, train = HDF.split_frame([.2])\n",
    "print('test set shape:', test.shape)\n",
    "print('train set shape:', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model And Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:41:59.083958",
     "start_time": "2017-02-08T07:40:33.110088"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Gridsearch returns no model due to bad parameter values or other reasons....",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9c485cbb5642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'default_flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hamelhusain/anaconda/envs/drpy3/lib/python3.5/site-packages/h2o/grid/grid_search.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, **params)\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y must be a single column reference'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"regressor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hamelhusain/anaconda/envs/drpy3/lib/python3.5/site-packages/h2o/grid/grid_search.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self, algo_params)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_auto_encoder\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y should not be specified for autoencoder.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_unsupervised\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_model_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hamelhusain/anaconda/envs/drpy3/lib/python3.5/site-packages/h2o/grid/grid_search.py\u001b[0m in \u001b[0;36m_model_build\u001b[0;34m(self, x, y, tframe, vframe, kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gridsearch returns no model due to bad parameter values or other reasons....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resolve_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Gridsearch returns no model due to bad parameter values or other reasons...."
     ]
    }
   ],
   "source": [
    "grid.train(x=features, y='default_flag', training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:42:01.534317",
     "start_time": "2017-02-08T07:42:01.301705"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_results = grid.get_grid(sort_by='logloss', decreasing=False)\n",
    "grid_results.sorted_metric_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:42:05.567006",
     "start_time": "2017-02-08T07:42:05.504679"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = grid_results[0]\n",
    "best_model.coef_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:42:15.315706",
     "start_time": "2017-02-08T07:42:15.016498"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holdout_preds = best_model.predict(test)['p1']\n",
    "holdout_eval = pd.concat([holdout_preds['p1'].as_data_frame(), test['default_flag'].as_data_frame()], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:42:43.339087",
     "start_time": "2017-02-08T07:42:43.332825"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('holdout log-loss:', log_loss(holdout_eval.default_flag.values, holdout_eval.p1.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best Model To Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must save path to disk, unfortunately I cannot specify the name of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is saved to this path:  /Users/hamelhusain/Dropbox/zidisha/models/zidisha_model_1\n"
     ]
    }
   ],
   "source": [
    "#the path the model is to be saved on\n",
    "model_save_path = '/Users/hamelhusain/Dropbox/zidisha/models/'\n",
    "#before we save the model, clear the directory of previous model\n",
    "shutil.rmtree(model_save_path)\n",
    "#save the model to the saved path\n",
    "saved_model = h2o.save_model(best_model, path = model_save_path)\n",
    "print('Model is saved to this path: ', saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model From Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inspect the model directory to retrieve the filename of the model object\n",
    "models = os.listdir(model_save_path)\n",
    "\n",
    "#check to make sure there is only one model object in the directory, if there \n",
    "# is no model file or there is more than one model then raise an error.  \n",
    "assert len(models) == 1, \\\n",
    "    ('Exactly one model must be present in path: {}\\n Clear this directory, retrain the model and try again'.\n",
    "     format(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: /Users/hamelhusain/Dropbox/zidisha/models/zidisha_model_1\n"
     ]
    }
   ],
   "source": [
    "#Construct the model's full path\n",
    "full_model_path = model_save_path + models[0]\n",
    "\n",
    "#print the full path for verfication and load model\n",
    "print('loading model from: {}'.format(full_model_path))\n",
    "final_model = h2o.load_model(full_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Model To Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#Load loans to be scored into H2o\n",
    "df_predict = pd.read_csv('/Users/hamelhusain/Dropbox/zidisha/for_predictions.csv')\n",
    "\n",
    "\n",
    "pred_col_types = ['int','int',\n",
    " 'int',\n",
    " 'int',\n",
    " 'int',\n",
    " 'int',\n",
    " 'int',\n",
    " 'real',\n",
    " 'real',\n",
    " 'enum',\n",
    " 'int',\n",
    " 'int',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'real',\n",
    " 'int']\n",
    "\n",
    "HDF_predict = HF.from_python(df_predict, column_types=pred_col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: | (failed)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Job with key $03017f00000132d4ffffffff$_b1b260b9a8ab1c1adfa3da61251548ea failed with an exception: java.lang.IllegalArgumentException: Test/Validation dataset has a non-categorical column 'reserve_fee_pct' which is categorical in the training data\nstacktrace: \njava.lang.IllegalArgumentException: Test/Validation dataset has a non-categorical column 'reserve_fee_pct' which is categorical in the training data\n\tat hex.Model.adaptTestForTrain(Model.java:865)\n\tat hex.Model.adaptTestForTrain(Model.java:747)\n\tat hex.Model.score(Model.java:959)\n\tat water.api.ModelMetricsHandler$1.compute2(ModelMetricsHandler.java:345)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1217)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-9d1ca73b0fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Make predictions on new loans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDF_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHDF_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Default_Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hamelhusain/anaconda/envs/drpy3/lib/python3.5/site-packages/h2o/model/model_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m    148\u001b[0m         j = H2OJob(h2o.api(\"POST /4/Predictions/models/%s/frames/%s\" % (self.model_id, test_data.frame_id)),\n\u001b[1;32m    149\u001b[0m                    self._model_json['algo'] + \" prediction\")\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hamelhusain/anaconda/envs/drpy3/lib/python3.5/site-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0;32m---> 76\u001b[0;31m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job with key %s failed with an exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000132d4ffffffff$_b1b260b9a8ab1c1adfa3da61251548ea failed with an exception: java.lang.IllegalArgumentException: Test/Validation dataset has a non-categorical column 'reserve_fee_pct' which is categorical in the training data\nstacktrace: \njava.lang.IllegalArgumentException: Test/Validation dataset has a non-categorical column 'reserve_fee_pct' which is categorical in the training data\n\tat hex.Model.adaptTestForTrain(Model.java:865)\n\tat hex.Model.adaptTestForTrain(Model.java:747)\n\tat hex.Model.score(Model.java:959)\n\tat water.api.ModelMetricsHandler$1.compute2(ModelMetricsHandler.java:345)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1217)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"
     ]
    }
   ],
   "source": [
    "#Make predictions on new loans\n",
    "predictions = HDF_predict.concat(final_model.predict(HDF_predict)['p1'].set_names(['Default_Prediction']))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export File progress: |███████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#Export data to csv\n",
    "h2o.export_file(predictions, '/Users/hamelhusain/Dropbox/zidisha/model_predictions.csv', force = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part 2 Experimental - Text Features (Ignore This Section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract text features from data frame and split into test vs. train set.  TODO:  use the same train/test split as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:57:03.278015",
     "start_time": "2017-02-08T07:57:03.100462"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamel_husain/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/hamel_husain/.local/lib/python3.5/site-packages/pandas/core/generic.py:4702: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/hamel_husain/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train (24912, 4)\n",
      "size of test (6228, 4)\n"
     ]
    }
   ],
   "source": [
    "df_text = df[text_fields + ['default_flag']]\n",
    "df_text.proposal_field[df.proposal_field.isnull()] = ''\n",
    "df_text_train, df_text_test = tts(df_text, test_size = .2)\n",
    "print('size of train', df_text_train.shape)\n",
    "print('size of test', df_text_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try two basic text vectorizers \n",
    "- Count Vectorizer (Bag of Words with frequency count)\n",
    "- TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer as Cvec\n",
    "enet = ElasticNetCV(l1_ratio = [.001, .01, .1, .5], cv = 5, normalize = True)\n",
    "tfidf = TFIDF(stop_words = 'english', min_df=.05, max_df = .95, sublinear_tf = True, ngram_range=(1, 4))\n",
    "cvec = Cvec(stop_words = 'english', min_df=.05, max_df = .95, ngram_range=(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:57:38.108790",
     "start_time": "2017-02-08T07:57:06.046359"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvec_dat = cvec.fit_transform(df_text_train.proposal_field)\n",
    "tfidf_data = tfidf.fit_transform(df_text_train.proposal_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:59:41.982561",
     "start_time": "2017-02-08T07:58:49.702011"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=None, copy_X=True, cv=5, eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=[0.001, 0.01, 0.1, 0.5], max_iter=1000, n_alphas=100,\n",
       "       n_jobs=1, normalize=True, positive=False, precompute='auto',\n",
       "       random_state=None, selection='cyclic', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet.fit(cvec_dat, df_text_train.default_flag)\n",
    "cvec_preds = enet.predict(cvec.transform(df_text_test.proposal_field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T08:01:05.060949",
     "start_time": "2017-02-08T08:01:05.052980"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss on holdout set (count vectorizer): 0.679630228373\n"
     ]
    }
   ],
   "source": [
    "print('log loss on holdout set (count vectorizer):', log_loss(df_text_test.default_flag, cvec_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T08:03:06.651056",
     "start_time": "2017-02-08T08:02:22.154749"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enet.fit(tfidf_data, df_text_train.default_flag)\n",
    "tfidf_preds = enet.predict(tfidf.transform(df_text_test.proposal_field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T08:03:20.382271",
     "start_time": "2017-02-08T08:03:20.375925"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss on holdout set (TFIDF vectorizer): 0.677721258792\n"
     ]
    }
   ],
   "source": [
    "print('log loss on holdout set (TFIDF vectorizer):', log_loss(df_text_test.default_flag, tfidf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:49:08.924867",
     "start_time": "2017-02-08T07:49:08.899704"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from sklearn import datasets, linear_model\n",
    ">>> from sklearn.cross_validation import cross_val_predict\n",
    ">>> diabetes = datasets.load_diabetes()\n",
    ">>> X = diabetes.data[:150]\n",
    ">>> y = diabetes.target[:150]\n",
    ">>> lasso = linear_model.Lasso()\n",
    ">>> y_pred = cross_val_predict(lasso, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T07:49:34.185267",
     "start_time": "2017-02-08T07:49:34.177832"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 174.26933996,  117.6539241 ,  164.60228641,  155.65049088,\n",
       "        132.68647979,  128.49511245,  120.76146877,  141.069413  ,\n",
       "        164.18904498,  182.37394949,  111.04181265,  127.94311443,\n",
       "        135.0869234 ,  162.83066014,  135.3573514 ,  157.64516523,\n",
       "        178.95843326,  163.3919841 ,  143.85237903,  144.29748882,\n",
       "        133.58117218,  124.77928571,  132.90918003,  208.52927   ,\n",
       "        153.61908967,  154.16616341,  118.95351821,  163.50467541,\n",
       "        145.89406196,  168.3308101 ,  155.87411031,  123.45960148,\n",
       "        185.70459144,  133.38468582,  117.2789469 ,  150.27895019,\n",
       "        174.1541028 ,  160.03235091,  192.31389633,  161.58568256,\n",
       "        154.2224809 ,  119.35517679,  146.15706413,  133.82056934,\n",
       "        179.68118754,  137.96619936,  146.07788398,  126.77579723,\n",
       "        123.32101099,  166.26710247,  146.41559964,  161.67261029,\n",
       "        147.47731459,  138.44595305,  144.85421048,  113.77990664,\n",
       "        185.54970402,  115.31624749,  142.23672103,  171.07792136,\n",
       "        132.5394716 ,  177.80524864,  116.5616502 ,  134.25230846,\n",
       "        142.88707475,  173.2830912 ,  154.31273504,  149.16680759,\n",
       "        144.88238997,  121.97783103,  110.38457621,  180.25559631,\n",
       "        199.06141058,  151.1195546 ,  161.14217698,  153.96960812,\n",
       "        150.77179755,  113.30903579,  165.15755771,  115.85735727,\n",
       "        174.19267171,  150.12027233,  115.47891783,  153.38967232,\n",
       "        115.31573467,  156.49909623,   92.62211515,  178.15649994,\n",
       "        131.59320715,  134.46166754,  116.97678633,  190.00790119,\n",
       "        166.01173292,  126.25944471,  134.29256991,  144.71971963,\n",
       "        190.9769591 ,  182.39199466,  154.45325308,  148.30325558,\n",
       "        151.72036937,  124.12825466,  138.6011155 ,  137.75891286,\n",
       "        123.0917243 ,  131.74735403,  112.07367481,  124.56956904,\n",
       "        156.78432061,  128.63135591,   93.68260079,  130.54324394,\n",
       "        131.8693231 ,  154.5708257 ,  179.81343019,  165.78130755,\n",
       "        150.04779033,  162.37974736,  143.92996797,  143.15645843,\n",
       "        125.20161377,  145.99590279,  155.3505536 ,  145.97574185,\n",
       "        134.66120515,  163.92450638,  101.92329396,  139.33014324,\n",
       "        122.71377023,  152.20573113,  153.36931089,  116.76545147,\n",
       "        131.96936127,  109.74817383,  132.57453994,  159.38030328,\n",
       "        109.31343881,  147.69926269,  156.3664255 ,  161.12509958,\n",
       "        128.16523686,  156.78446286,  154.04375702,  124.83705022,\n",
       "        143.85606595,  143.23651701,  147.76316913,  154.21572891,\n",
       "        129.07895017,  157.79644923])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-08T08:08:32.734494",
     "start_time": "2017-02-08T08:08:32.598460"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hamel_husain/Dropbox/zidisha\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:drpy3]",
   "language": "python",
   "name": "conda-env-drpy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
